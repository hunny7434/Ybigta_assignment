{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beADODeGPe7H"
   },
   "source": [
    "## Pandas 과제\n",
    "\n",
    "Tabular data의 경우 모델을 돌리기에 앞서서 pandas를 통한 전처리가 많이 필요합니다.\n",
    "\n",
    "다음 과제에서는 판다스에서 가장 자주 쓰이는 함수들을 다룹니다.\n",
    "\n",
    "구글에 올라와 있는 판다스 연습문제 200제 중 중복되는 것, 불필요하다고 생각되는 것을 제외하여 과제를 만들게 되었습니다.\n",
    "\n",
    "넘파이 관련 문제들도 있었지만 판다스로만 과제를 구성하게 되었고, 그것들도 풀어보고 싶은 분들은 아래 출처를 남겨 놓았으니 참고하세요.\n",
    "\n",
    "약 150개 정도로 문제 수가 많지만 기초적인 문제들이 많기 때문에 시간이 좀 걸릴 뿐 큰 어려움은 없을 거라 생각합니다.\n",
    "\n",
    "문제를 풀다보면 부자연스러운 문제도 많이 있지만 그냥 연습 삼아 풀어보시기 바랍니다.\n",
    "\n",
    "관련 csv파일들은 별도의 파일에 담아놓았습니다.\n",
    "\n",
    "\n",
    " 발제자: DA 23기 양진성\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDnagT4ZPe7J"
   },
   "source": [
    "### 출처\n",
    "\n",
    "Author: Avi Chawla\n",
    "\n",
    "LinkedIn: https://www.linkedin.com/in/avi-chawla/\n",
    "\n",
    "Read my blogs here: https://medium.com/@avi_chawla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQ80fJBVPe7K"
   },
   "source": [
    "- **Pandas**\n",
    "\n",
    "1. Pandas Notebook 1: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Pandas-Notebook-1-d693ac55-6455-40cf-ae34-867c6a02014e/%2Fnotebook.ipynb)\n",
    "2. Pandas Notebook 2: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Pandas-Notebook-employee-dataset-7e3b6755-5d4b-464b-9b75-9c84667ae3bd/%2Fnotebook.ipynb)\n",
    "\n",
    "3. Pandas Notebook 3: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Pandas-Notebook-employee-part-2-adc5a3ee-5f61-4725-8e46-ccb07899acfc/%2Fnotebook.ipynb)\n",
    "\n",
    "4. Pandas Notebook 4: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Pandas-after-employee-f84e02a1-fb6a-428e-af90-8dd99855749a/%2Fnotebook.ipynb) **(This Notebook)**\n",
    "\n",
    "- **NumPy**\n",
    "\n",
    "1. NumPy Notebook 1: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Numpy-part-1-9b9979f2-b708-4292-b466-3d0157564c91/%2Fnotebook.ipynb)\n",
    "\n",
    "2. NumPy Notebook 2: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/NumPy-Notebook-2-4456411e-2ddd-426d-8027-4881080027db/%2Fnotebook.ipynb)\n",
    "\n",
    "3. NumPy Notebook 3: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/NumPy-Notebook-3-e6587114-b580-4249-b599-540de859e603/%2Fnotebook.ipynb)\n",
    "\n",
    "- **SQL**\n",
    "\n",
    "1. SQL Notebook 1: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/SQL-Notebook-1-eac9d782-a9b1-4e84-a1f9-af14080a6121/%2Fnotebook.ipynb)\n",
    "\n",
    "2. SQL Notebook 2: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/SQL-Notebook-2-1914b214-be03-44a1-be63-ad99e98be639/%2Fnotebook.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bac3049910b240b998ba02c52dd9a7cf",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "KykzE1swPe7L"
   },
   "source": [
    "# Pandas Notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "allow_embed": "code",
    "cell_id": "1247c98b228f4e26a7e645554d1444a0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1659984470280,
    "source_hash": "c76c7c51",
    "tags": [],
    "id": "rTuCOmrsPe7L",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704858385115,
     "user_tz": -540,
     "elapsed": 437,
     "user": {
      "displayName": "[20_HG001Y]이상헌",
      "userId": "03316205016909977920"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:12.598987Z",
     "start_time": "2024-01-10T15:39:10.514555Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6aaba47726e04be19708d622e44b4594",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "wkXGQ6jrPe7M"
   },
   "source": [
    "## Create a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5134b361d40a48629147a7607e50e333",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "O1s0ril2Pe7N"
   },
   "source": [
    "### 1. Create a DataFrame from a list of lists. Name the columns \"col1\", \"col2\" and \"col3\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "cell_id": "e4de38de7b714b368a3ad2cea933f99f",
    "deepnote_cell_height": 115,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "H8SnBl84Pe7O",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704858489452,
     "user_tz": -540,
     "elapsed": 303,
     "user": {
      "displayName": "[20_HG001Y]이상헌",
      "userId": "03316205016909977920"
     }
    },
    "outputId": "1bb84669-b5fd-4afe-a9aa-3e376f0c9b89",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:12.631983Z",
     "start_time": "2024-01-10T15:39:12.597346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     2     3\n",
      "1     4     5     6\n"
     ]
    }
   ],
   "source": [
    "data_list = [[1,2,3], [4,5,6]]\n",
    "\n",
    "df = pd.DataFrame( data_list, columns = ['col1', 'col2', 'col3'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f24b2e095a234294b4782e696a6e5d5a",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "E4pMxJivPe7P"
   },
   "source": [
    "### 2. Create a DataFrame from a list of lists. Name the columns \"col1\", \"col2\" and \"col3\". Change the data type of all columns to \"int8\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "cell_id": "97d8b0c0c0f744fdb856d6fa4acf3ba8",
    "deepnote_cell_height": 133,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "GtR-rEdSPe7P",
    "outputId": "c33181de-ba87-422c-f335-2790489e5f9e",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:12.734964Z",
     "start_time": "2024-01-10T15:39:12.626271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     2     3\n",
      "1     4     5     6\n",
      "col1    int8\n",
      "col2    int8\n",
      "col3    int8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_list = [[1,2,3], [4,5,6]]\n",
    "\n",
    "df = pd.DataFrame( data_list, columns = ['col1', 'col2', 'col3'], dtype = np.int8)\n",
    "print(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "67608c871eff4c13b387c01d90efb01b",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "Du_NbLAlPe7Q"
   },
   "source": [
    "### 3. Create a DataFrame from a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "cell_id": "af6e6be1179c4a619e99a2ffc72fe2ec",
    "deepnote_cell_height": 115,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "Bb6CWBZAPe7Q",
    "outputId": "3ea70595-d889-4de5-bfad-e70d9957da73",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:12.771158Z",
     "start_time": "2024-01-10T15:39:12.728720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "0     1     3\n",
      "1     2     4\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data=data_dict)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "10a39af80da44666b7cd6b7c76598868",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "wlJa7ZlfPe7Q"
   },
   "source": [
    "### 4. Create a DataFrame from a dictionary. Change the data type to \"int8\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "cell_id": "7db3f0b16fa046df8b556fab1f924448",
    "deepnote_cell_height": 133,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "I7QqJqrBPe7R",
    "outputId": "b0f13ebb-ff65-4f71-9ea2-3f5b6c777a12",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:12.887298Z",
     "start_time": "2024-01-10T15:39:12.760376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "0     1     3\n",
      "1     2     4\n",
      "col1    int8\n",
      "col2    int8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data=data_dict, dtype = np.int8)\n",
    "print(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c4f04239427b4dfeb371b7f85167aa59",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "jcc02BedPe7R"
   },
   "source": [
    "### 5. Create a DataFrame from a numpy array. Name the columns \"col1\", \"col2\" and \"col3\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "cell_id": "6db2cc59b35d44308ee927877e504b67",
    "deepnote_cell_height": 115,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "6LtDEnvXPe7R",
    "outputId": "190fffe3-3ec8-4c74-8fb2-3670f9da0163",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:12.938712Z",
     "start_time": "2024-01-10T15:39:12.871472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     2     3\n",
      "1     4     5     6\n"
     ]
    }
   ],
   "source": [
    "data_nparray = np.array([[1,2,3], [4,5,6]])\n",
    "\n",
    "df = pd.DataFrame(data_nparray, columns = ['col1', 'col2', 'col3'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "de1e8331c49f4f5c93f0c72c4b7ba203",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "3N9Xe_ZiPe7S"
   },
   "source": [
    "## Input Operations from CSV in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "141fc7656f334da2bbb5d43f40bec4c2",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "YKakQqVvPe7S"
   },
   "source": [
    "### 6. Read a CSV File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "cell_id": "7d5f6e2c60c741ab9f5fae8b7bf5feb0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1659896158632,
    "source_hash": "b623e53d",
    "tags": [],
    "id": "u_F5HmvgPe7T",
    "outputId": "4fbd1e3a-6e2f-499e-d6f9-2c442234ea0e",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.072870Z",
     "start_time": "2024-01-10T15:39:12.930406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     2     3\n",
      "1     4     5     6\n",
      "2     7     8     9\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"input_data/file1.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8f9a70588d944fd78abeea0971687a56",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "g90sJh5kPe7T"
   },
   "source": [
    "### 7. Read a CSV file with delimiter \"|\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "cell_id": "0f8de42d5a9b4909b6c21941137d5b04",
    "deepnote_cell_height": 115,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "BeKTQdcmPe7T",
    "outputId": "7e47983f-e22f-4216-c014-30e2cfb20073",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.109569Z",
     "start_time": "2024-01-10T15:39:13.058154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     2     3\n",
      "1     4     5     6\n",
      "2     7     8     9\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"input_data/file2.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file, delimiter='|')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2c4f52473db24da6baa0a5129e176a59",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "kQCSSLicPe7U"
   },
   "source": [
    "### 8. Read a CSV file with no header column and use \"col1\", \"col2\" and \"col3\" as column names. The delimiter is \",\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "cell_id": "e84bf940f16945cd9d91441af3658be3",
    "deepnote_cell_height": 115,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "P-EtPMFOPe7U",
    "outputId": "9def46b4-59d5-4c7d-c010-66dff3419aee",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.228156Z",
     "start_time": "2024-01-10T15:39:13.101360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     2     3\n",
      "1     4     5     6\n",
      "2     7     8     9\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"input_data/file3.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file, names = ['col1', 'col2', 'col3'],header=None, delimiter=',')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4842addbe893458f80df0837f055a5fa",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "BrFL-jkpPe7U"
   },
   "source": [
    "### 9. There are 3 columns in the file, namely \"col1\", \"col2\", and \"col3\". You have to read only \"col1\" and \"col3\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "cell_id": "602030d5cc4047efba6be2bb7084e468",
    "deepnote_cell_height": 115,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "g6-gASVZPe7V",
    "outputId": "f26ae8da-778e-4ad4-b825-6adb4d23be24",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.262387Z",
     "start_time": "2024-01-10T15:39:13.213679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col3\n",
      "0     1     3\n",
      "1     4     6\n",
      "2     7     9\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"input_data/file1.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file, usecols=[\"col1\", \"col3\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7810864401e849a2984e5287d89be7bc",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "940C9oE1Pe7V"
   },
   "source": [
    "### 10. There are 3 columns in the file, namely \"col1\", \"col2\", and \"col3\". You have to read only \"col1\" and \"col3\". Moreover, the delimiter is \"|\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "cell_id": "212e480c629b4a0e8949dc763a78b44b",
    "deepnote_cell_height": 115,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "sRHk1bqbPe7V",
    "outputId": "7783c150-3f21-4f4b-b912-91e36e402e8d",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.362233Z",
     "start_time": "2024-01-10T15:39:13.255873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col3\n",
      "0     1     3\n",
      "1     4     6\n",
      "2     7     9\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"input_data/file2.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file, usecols=[\"col1\", \"col3\"], delimiter='|')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1311297a04c94a60b908f99e5f355fa4",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "QEYVqQlvPe7V"
   },
   "source": [
    "### 11. The file \"file4.csv\" has junk characters in the first two lines. You have to read the CSV file from the 3rd line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "cell_id": "99001d5c13b944c0a9c833b621cd995c",
    "deepnote_cell_height": 115,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "_rMsJnt_Pe7W",
    "outputId": "ceea9481-e231-4e5a-896b-8b95825b2648",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.406199Z",
     "start_time": "2024-01-10T15:39:13.346196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     2     3\n",
      "1     4     5     6\n",
      "2     7     8     9\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"input_data/file4.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file, skiprows = 2)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e1b751a1ad2c4a08b4434020f09a6dc9",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "l1gAeKEWPe7W"
   },
   "source": [
    "### 12. There are 3 columns in the file, namely \"col1\", \"col2\", and \"col3\". While reading the CSV file, specify the data type of \"col1\" as 'int32'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "cell_id": "3193f911f1194a71a3de98cdbcf1fe8b",
    "deepnote_cell_height": 115,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "8TO1Mc9IPe7W",
    "outputId": "e718622c-e16e-4a3b-b0ae-adbf2042306c",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.552258Z",
     "start_time": "2024-01-10T15:39:13.404470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     2     3\n",
      "1     4     5     6\n",
      "2     7     8     9\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"input_data/file1.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file, dtype={\"col1\": \"int32\"})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1056a6c67708428cac87081b592c3acf",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "z3ENfAv8Pe7W"
   },
   "source": [
    "### 13. The first column in the CSV file holds index values of the dataframe. Read it so that the first column goes as the index column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "cell_id": "6b910dc50ef14e558183ece164dd34e7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1659897460042,
    "source_hash": "6f4f6738",
    "tags": [],
    "id": "CY2m5g6gPe7X",
    "outputId": "4096a6c2-940d-4cce-f17e-0730e77daead",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.587875Z",
     "start_time": "2024-01-10T15:39:13.522070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     2     3\n",
      "1     4     5     6\n",
      "2     7     8     9\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"input_data/file5.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file, index_col=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "749a612e37d5450fa50cbbb1069605fa",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "P6NA0Iu9Pe7X"
   },
   "source": [
    "### 14. There are 9 data rows in the CSV file. Read only the first 4 of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ed48b92ae82e461190405bad227fd38e",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 100
     }
    ],
    "is_collapsed": false,
    "tags": [],
    "id": "JJ0Oo_KuPe7X"
   },
   "source": [
    "Note: You should NOT read the whole CSV file and use the head() method to select the first 4 rows. 🚫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "cell_id": "31944423ea9f473eb632efa25beb1e3a",
    "deepnote_cell_height": 115,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "xj8-6FE-Pe7Y",
    "outputId": "935720a5-803b-497c-8a9e-72cdc3e6a28c",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.695544Z",
     "start_time": "2024-01-10T15:39:13.580636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     2     3\n",
      "1     4     5     6\n",
      "2     7     8     9\n",
      "3     1     2     3\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"input_data/file6.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file).head(4)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b868eef4ed9745ddb43d318872c2b544",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "Ia9jtNaIPe7Y"
   },
   "source": [
    "## Output Operations to CSV in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4b17329401414c36856ca40b2b8dcbdc",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "UXuPWB7RPe7Y"
   },
   "source": [
    "### 16. Given the dataframe \"df\", store it to a CSV File (with the index values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "cell_id": "b20aa89229a7415faacffa8aa7005698",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1659898703469,
    "source_hash": "a0acabfa",
    "tags": [],
    "id": "7w7NW4jwPe7Y",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.730452Z",
     "start_time": "2024-01-10T15:39:13.681249Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,2,3], [4,5,6]],\n",
    "                  columns = [\"col1\", \"col2\", \"col3\"])\n",
    "\n",
    "csv_file = \"output_data/file1.csv\"\n",
    "\n",
    "## Start your code here\n",
    "\n",
    "df.to_csv(csv_file, index=True)\n",
    "\n",
    "## End your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "87c763b753ee4fbfa191b663c4830fc8",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "-yyF5XxzPe7Z"
   },
   "source": [
    "### 17. Given the dataframe \"df\", store it to a CSV File without the index column this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "cell_id": "55d0e76c18d4462aa24a9f76a4560f48",
    "deepnote_cell_height": 241,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "qx2FkS6XPe7Z",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.835303Z",
     "start_time": "2024-01-10T15:39:13.723077Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,2,3], [4,5,6]],\n",
    "                  columns = [\"col1\", \"col2\", \"col3\"])\n",
    "\n",
    "csv_file = \"output_data/file2.csv\"\n",
    "\n",
    "## Start your code here\n",
    "\n",
    "df.to_csv(csv_file, index=False)\n",
    "\n",
    "## End your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6b27e6de89e44613a9a0b497fd8a96a0",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": [],
    "id": "I1u3GsTGPe7Z"
   },
   "source": [
    "### 20. Given a dataframe \"df\" with three columns -- \"col1\", \"col2\" and \"col3\". Store the DataFrame to a CSV file without the column row ( and without the index values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "cell_id": "52df84f7732a4015a50c32a98328d324",
    "deepnote_cell_height": 241,
    "deepnote_cell_type": "code",
    "tags": [],
    "id": "vqsWycSQPe7a",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.871227Z",
     "start_time": "2024-01-10T15:39:13.819520Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,2,3], [4,5,6]],\n",
    "                  columns = [\"col1\", \"col2\", \"col3\"])\n",
    "\n",
    "csv_file = \"output_data/file5.csv\"\n",
    "\n",
    "\n",
    "## Start your code here\n",
    "\n",
    "df.to_csv(csv_file, header=False, index=False)\n",
    "\n",
    "## End your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8MPhhTyPe7a"
   },
   "source": [
    "# Pandas Notebook 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRFI2tUFPe7a"
   },
   "source": [
    "### 31. Read the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "id": "PJY-gpfTPe7a",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:13.953638Z",
     "start_time": "2024-01-10T15:39:13.869184Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "id": "RuZ1cwTZPe7b",
    "outputId": "a7f06ea8-a171-4677-c670-95acce9dfe6e",
    "executionInfo": {
     "status": "error",
     "timestamp": 1704558716608,
     "user_tz": -540,
     "elapsed": 351,
     "user": {
      "displayName": "이건(인공지능융합대학 컴퓨터과학과)",
      "userId": "02124061071315431838"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.255253Z",
     "start_time": "2024-01-10T15:39:13.951348Z"
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"employee_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv('input_data/' + file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M98JN2YiPe7b"
   },
   "source": [
    "### 32. Print the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "id": "O2PCwb1uPe7b",
    "outputId": "e2f8be26-1603-4c69-95cb-a44a5f7bbaa4",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.267756Z",
     "start_time": "2024-01-10T15:39:14.196193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name                  Company_Name  \\\n",
      "0  Spencer Adkins                James and Sons   \n",
      "1    Julie Morton                 Nichols-James   \n",
      "2    Matthew Hall                     Scott Inc   \n",
      "3      Brad Scott  Johnston, Fleming and Tanner   \n",
      "4   Theresa Owens      Baker, Allen and Edwards   \n",
      "\n",
      "                        Employee_Job_Title      Employee_City  \\\n",
      "0                          Equities trader     New Russellton   \n",
      "1  Diplomatic Services operational officer  North Melissafurt   \n",
      "2               Regulatory affairs officer           Wardfort   \n",
      "3                      Production engineer     West Jamesview   \n",
      "4                      Production engineer          Whiteside   \n",
      "\n",
      "        Employee_Country  Employee_Salary Employment_Status  Employee_Rating  \n",
      "0  Palestinian Territory           321520         Full Time              3.9  \n",
      "1       Marshall Islands           589090         Full Time              4.3  \n",
      "2               Anguilla           630890         Full Time              3.1  \n",
      "3   Syrian Arab Republic           116400         Full Time              3.1  \n",
      "4               Dominica           523499         Full Time              4.8  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQcqyqLJPe7c"
   },
   "source": [
    "### 33. Print the last 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "id": "GKJy1iypPe7c",
    "outputId": "c83118ac-5da3-40e6-a298-b22c89341ff4",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.283360Z",
     "start_time": "2024-01-10T15:39:14.199599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Name                  Company_Name  \\\n",
      "299990      Monica Bender    Wallace, Smith and Shepard   \n",
      "299991  William Rodriguez                     Scott Inc   \n",
      "299992    Steven Thornton      Baker, Allen and Edwards   \n",
      "299993         Terry Hill       White, Mcclain and Cobb   \n",
      "299994      Kelly Bennett       White, Mcclain and Cobb   \n",
      "299995         Nancy Neal              Bullock-Carrillo   \n",
      "299996     Michele Butler  Johnston, Fleming and Tanner   \n",
      "299997        Lynn Wilson                 Nichols-James   \n",
      "299998      Lindsey Keith                 Nichols-James   \n",
      "299999      Karen Delgado                James and Sons   \n",
      "\n",
      "                  Employee_Job_Title      Employee_City Employee_Country  \\\n",
      "299990           Production engineer   New Cindychester       Bangladesh   \n",
      "299991                    Ergonomist          Whiteside      New Zealand   \n",
      "299992               Patent examiner         Aliciafort            Benin   \n",
      "299993  Investment banker, corporate   New Cindychester           Sweden   \n",
      "299994     Radiographer, therapeutic           Wardfort             Fiji   \n",
      "299995                   Optometrist  North Melissafurt            Samoa   \n",
      "299996                 Administrator         Aliciafort             Cuba   \n",
      "299997                 Administrator   New Cindychester          Bolivia   \n",
      "299998                          Make       Whitakerbury   Western Sahara   \n",
      "299999                       Actuary     New Russellton   United Kingdom   \n",
      "\n",
      "        Employee_Salary Employment_Status  Employee_Rating  \n",
      "299990           852660         Full Time              3.0  \n",
      "299991           214400         Full Time              1.5  \n",
      "299992            60240         Full Time              4.3  \n",
      "299993           414720            Intern              2.3  \n",
      "299994           182270         Full Time              3.6  \n",
      "299995            99670            Intern              3.3  \n",
      "299996           949580            Intern              2.6  \n",
      "299997           802830         Full Time              0.6  \n",
      "299998           257240         Full Time              2.4  \n",
      "299999           575770            Intern              3.3  \n"
     ]
    }
   ],
   "source": [
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ09-bBsPe7c"
   },
   "source": [
    "### 34. Print the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "id": "KuObAWtcPe7c",
    "outputId": "20954792-2c87-4e25-ec9e-917b25da20fa",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.287759Z",
     "start_time": "2024-01-10T15:39:14.202388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "rows = df.shape[0]\n",
    "\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36z79pvEPe7d"
   },
   "source": [
    "### 35. Print the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "id": "gNnJ2DVPPe7d",
    "outputId": "d5eaba2c-3f0b-4d04-dea8-e8cc708cbbff",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.291858Z",
     "start_time": "2024-01-10T15:39:14.204504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "columns = df.shape[1]\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZaHhchmPe7d"
   },
   "source": [
    "### 36. Print all column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "id": "znaznLAQPe7e",
    "outputId": "e63403b2-a517-46cc-ca56-f3c8b5fe3576",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.296102Z",
     "start_time": "2024-01-10T15:39:14.206593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Company_Name', 'Employee_Job_Title', 'Employee_City',\n",
      "       'Employee_Country', 'Employee_Salary', 'Employment_Status',\n",
      "       'Employee_Rating'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "column_names = df.columns\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eZLfNvJPe7e"
   },
   "source": [
    "### 37. Print the mean of Employee_Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "id": "c-eQJUmhPe7e",
    "outputId": "1ff5c6e6-2080-4451-8912-ba4f63548147",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.305736Z",
     "start_time": "2024-01-10T15:39:14.209218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500224.20772666665\n"
     ]
    }
   ],
   "source": [
    "print(df['Employee_Salary'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HO3LQ_f-Pe7f"
   },
   "source": [
    "### 38. Print the mean of Employee_Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "id": "2s3dR7QIPe7f",
    "outputId": "67038b7f-3dd2-4801-d70f-5fe067346592",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.496992Z",
     "start_time": "2024-01-10T15:39:14.257641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5059550000000006\n"
     ]
    }
   ],
   "source": [
    "print(df['Employee_Rating'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtFXGUC-Pe7f"
   },
   "source": [
    "### 39. Print the number of distinct Company_Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "id": "sPow8DB7Pe7f",
    "outputId": "c9498c07-4e00-45ee-a873-4e846b4f03d2",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.619596Z",
     "start_time": "2024-01-10T15:39:14.483176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(df['Company_Name'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF38vWT_Pe7g"
   },
   "source": [
    "### 41. Print the number of employees working in the company \"Nichols-James\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "id": "pfd8wPtvPe7g",
    "outputId": "f1280e9f-e1d3-4a1e-843f-7aff579ca8cc",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.743881Z",
     "start_time": "2024-01-10T15:39:14.616203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19911\n"
     ]
    }
   ],
   "source": [
    "print(df[df['Company_Name'] == 'Nichols-James'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKzNLeK-Pe7g"
   },
   "source": [
    "### 42-44. Print the maximum, minimum and median Employee_Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "id": "a7lZQiOfPe7h",
    "outputId": "2ae39ddb-70f2-4a76-eba8-bf9b86f56cfa",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.765652Z",
     "start_time": "2024-01-10T15:39:14.716592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999990\n",
      "0\n",
      "500780.0\n"
     ]
    }
   ],
   "source": [
    "print(df['Employee_Salary'].max())\n",
    "print(df['Employee_Salary'].min())\n",
    "print(df['Employee_Salary'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhA9d_HBPe7h"
   },
   "source": [
    "### 45-49. Print the distribution of the following columns: (the frequency of individual entries)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmkYNF-qPe7h"
   },
   "source": [
    "1. Company_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "id": "StXexFd3Pe7i",
    "outputId": "cba5807a-7e98-49b1-9497-68498da8d33b",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.906640Z",
     "start_time": "2024-01-10T15:39:14.768738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company_Name\n",
      "Scott Inc                         20390\n",
      "White, Mcclain and Cobb           20261\n",
      "Thomas-Spencer                    20142\n",
      "Nelson-Li                         20132\n",
      "Taylor-Ramos                      20122\n",
      "Baker, Allen and Edwards          20084\n",
      "Matthews Inc                      20083\n",
      "Bullock-Carrillo                  20063\n",
      "Andrade LLC                       19983\n",
      "Campos, Reynolds and Mccormick    19927\n",
      "Nichols-James                     19911\n",
      "James and Sons                    19868\n",
      "Marshall-Holloway                 19859\n",
      "Johnston, Fleming and Tanner      19811\n",
      "Wallace, Smith and Shepard        19364\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Company_Name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbmPWWYdPe7i"
   },
   "source": [
    "2. Employee_Job_Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "id": "mUZmERtrPe7i",
    "outputId": "d13e9293-b63a-48e0-8ab8-b50a89cab31e",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:14.929713Z",
     "start_time": "2024-01-10T15:39:14.898692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee_Job_Title\n",
      "Diplomatic Services operational officer                  30137\n",
      "Administrator                                            15222\n",
      "Garment/textile technologist                             15183\n",
      "Trading standards officer                                15155\n",
      "Patent examiner                                          15085\n",
      "Armed forces logistics/support/administrative officer    15050\n",
      "Retail merchandiser                                      15033\n",
      "Energy manager                                           15033\n",
      "Actuary                                                  15030\n",
      "Investment banker, corporate                             15008\n",
      "Ergonomist                                               15006\n",
      "Production engineer                                      15003\n",
      "Equities trader                                          15000\n",
      "Naval architect                                          14905\n",
      "Radiographer, therapeutic                                14882\n",
      "Regulatory affairs officer                               14869\n",
      "Optometrist                                              14838\n",
      "Sales promotion account executive                        14820\n",
      "Make                                                     14741\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Employee_Job_Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2EiOe2yPe7j"
   },
   "source": [
    "### 50. Print the company with the most number of employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "id": "o6tZBNTiPe7j",
    "outputId": "4d358203-4047-4e03-809c-41b84441eef6",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.068131Z",
     "start_time": "2024-01-10T15:39:14.937980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scott Inc\n"
     ]
    }
   ],
   "source": [
    "print(df['Company_Name'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loGRB7JnPe7j"
   },
   "source": [
    "### 51. Print the number of employees in the above company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "id": "VYcL64IzPe7j",
    "outputId": "855b5144-0e02-491e-fd04-d47146e4a344",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.153667Z",
     "start_time": "2024-01-10T15:39:15.046097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20390\n"
     ]
    }
   ],
   "source": [
    "print(df['Company_Name'].value_counts().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XKdd2P1Pe7k"
   },
   "source": [
    "### 52. Print the company with the least number of employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "id": "JRHYqgqHPe7k",
    "outputId": "9d2d6862-cb2e-419f-9eab-c2f43a843812",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.192045Z",
     "start_time": "2024-01-10T15:39:15.149794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wallace, Smith and Shepard\n"
     ]
    }
   ],
   "source": [
    "print(df['Company_Name'].value_counts().idxmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWV2nS53Pe7k"
   },
   "source": [
    "### 53. Print the number of employees in the above company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "id": "gCgzjRSDPe7l",
    "outputId": "4f1dd362-b0a8-44f5-b941-c3b480f4fe9a",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.312191Z",
     "start_time": "2024-01-10T15:39:15.199807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19364\n"
     ]
    }
   ],
   "source": [
    "print(df['Company_Name'].value_counts().min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vwt8jEUlPe7l"
   },
   "source": [
    "### 54. Print the employee details with the maximum salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "id": "E_KOJFbUPe7l",
    "outputId": "f5de4eee-e994-4130-e5ef-e32875f9f3f4",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.336652Z",
     "start_time": "2024-01-10T15:39:15.276366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name  Company_Name   Employee_Job_Title Employee_City  \\\n",
      "70356  Anna Lawson  Taylor-Ramos  Production engineer   Kristaburgh   \n",
      "\n",
      "      Employee_Country  Employee_Salary Employment_Status  Employee_Rating  \n",
      "70356          Lesotho           999990         Full Time              4.0  \n"
     ]
    }
   ],
   "source": [
    "print(df[df['Employee_Salary'] == df['Employee_Salary'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3gwGGlnPe7l"
   },
   "source": [
    "### 55. Print the employee details with the maximum rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "id": "3yPotJ-MPe7m",
    "outputId": "d02434d5-d04e-44fd-cad2-bff930c4b220",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.456943Z",
     "start_time": "2024-01-10T15:39:15.334656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name                  Company_Name  \\\n",
      "124       Joshua Huffman                James and Sons   \n",
      "342         Alan Carlson      Baker, Allen and Edwards   \n",
      "391         Lisa Summers  Johnston, Fleming and Tanner   \n",
      "395        Timothy Woods  Johnston, Fleming and Tanner   \n",
      "415      Cameron Hawkins                  Taylor-Ramos   \n",
      "...                  ...                           ...   \n",
      "299689    Michael Jordan  Johnston, Fleming and Tanner   \n",
      "299855  Rebecca Garrison                     Nelson-Li   \n",
      "299900      Daniel Jones                  Taylor-Ramos   \n",
      "299906     Justin Mendez              Bullock-Carrillo   \n",
      "299973      Doris Miller                   Andrade LLC   \n",
      "\n",
      "                                       Employee_Job_Title      Employee_City  \\\n",
      "124                          Garment/textile technologist     New Russellton   \n",
      "342               Diplomatic Services operational officer        Kristaburgh   \n",
      "391                            Regulatory affairs officer  North Melissafurt   \n",
      "395                          Garment/textile technologist          Whiteside   \n",
      "415     Armed forces logistics/support/administrative ...           Wardfort   \n",
      "...                                                   ...                ...   \n",
      "299689                                    Naval architect       Whitakerbury   \n",
      "299855                                Production engineer       Whitakerbury   \n",
      "299900                  Sales promotion account executive        Kristaburgh   \n",
      "299906                         Regulatory affairs officer   New Cindychester   \n",
      "299973  Armed forces logistics/support/administrative ...           Wardfort   \n",
      "\n",
      "                    Employee_Country  Employee_Salary Employment_Status  \\\n",
      "124                     Cook Islands           694760         Full Time   \n",
      "342                         Mongolia           491710            Intern   \n",
      "391                             Togo           933500         Full Time   \n",
      "395     United States Virgin Islands           367630         Full Time   \n",
      "415                         Tanzania            66570            Intern   \n",
      "...                              ...              ...               ...   \n",
      "299689                   Philippines           474540         Full Time   \n",
      "299855                       Ireland           592530         Full Time   \n",
      "299900                  Sierra Leone            32160         Full Time   \n",
      "299906                      Colombia           374540         Full Time   \n",
      "299973                    Kazakhstan           943340            Intern   \n",
      "\n",
      "        Employee_Rating  \n",
      "124                 5.0  \n",
      "342                 5.0  \n",
      "391                 5.0  \n",
      "395                 5.0  \n",
      "415                 5.0  \n",
      "...                 ...  \n",
      "299689              5.0  \n",
      "299855              5.0  \n",
      "299900              5.0  \n",
      "299906              5.0  \n",
      "299973              5.0  \n",
      "\n",
      "[2985 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[df['Employee_Rating'] == df['Employee_Rating'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgz8LldiPe7m"
   },
   "source": [
    "### 56. Print the Company_Name with most number of employees in 'Wardfort' city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "id": "aU9l8U7oPe7m",
    "outputId": "be87ee64-a8f8-4a79-938f-6d87474ed61f",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.539494Z",
     "start_time": "2024-01-10T15:39:15.450666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White, Mcclain and Cobb\n"
     ]
    }
   ],
   "source": [
    "wardfort_employees = df[df['Employee_City'] == 'Wardfort']\n",
    "\n",
    "print(wardfort_employees['Company_Name'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_doqegn7Pe7m"
   },
   "source": [
    "### 57. Change the Data type of 'Employee_Salary' column to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "id": "lFtrj_JvPe7n",
    "outputId": "9ef53ee2-bfda-484c-8a56-6dfba1dded04",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.564492Z",
     "start_time": "2024-01-10T15:39:15.480564Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Employee_Salary'] = df['Employee_Salary'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPsIGcWFPe7n"
   },
   "source": [
    "### 58. Print the Employee_City with the most number of 'Production engineer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "id": "KPbD3ZwiPe7n",
    "outputId": "d360ae7f-2e41-4b66-e941-ec6e11b8c47b",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.704344Z",
     "start_time": "2024-01-10T15:39:15.572417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliciafort\n"
     ]
    }
   ],
   "source": [
    "production_engineers = df[df['Employee_Job_Title'] == 'Production engineer']\n",
    "print(production_engineers['Employee_City'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKOu4R3ZPe7o"
   },
   "source": [
    "### 60. Print the Company_Name with the highest average 'Employee_Rating'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "id": "T_DF6WMMPe7o",
    "outputId": "54785322-e4bc-4eb8-cf98-4b5721982ed1",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.747668Z",
     "start_time": "2024-01-10T15:39:15.690888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Inc\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('Company_Name')['Employee_Rating'].mean().idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plWyodOaPe7o"
   },
   "source": [
    "### 61. Print the number of employees working in 'Ricardomouth' and 'Kristaburgh' location combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "id": "1mvb7kg4Pe7o",
    "outputId": "9a82addf-87c0-451d-f4ea-14d26cae04cd",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.869682Z",
     "start_time": "2024-01-10T15:39:15.746681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60256\n"
     ]
    }
   ],
   "source": [
    "employees = df[df['Employee_City'].isin(['Ricardomouth', 'Kristaburgh'])]\n",
    "print(employees.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryie2eUbPe7p"
   },
   "source": [
    "### 62. Print the distinct Company_Name corresponding to the 5 highest paid employees in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "id": "Ft5TXbjwPe7p",
    "outputId": "257c3b47-c21a-442d-c764-2df103d71e7f",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:15.983567Z",
     "start_time": "2024-01-10T15:39:15.841283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Taylor-Ramos' 'Thomas-Spencer' 'White, Mcclain and Cobb'\n",
      " 'Campos, Reynolds and Mccormick']\n"
     ]
    }
   ],
   "source": [
    "employees = df.sort_values(by='Employee_Salary', ascending=False).head(5)\n",
    "\n",
    "print(employees['Company_Name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fR8doOxpPe7p"
   },
   "source": [
    "### 63. Check if there are any duplicate rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "id": "KppX5uQUPe7p",
    "outputId": "b37b4cac-c376-41c2-d62a-bfe011b85cfd",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:16.102016Z",
     "start_time": "2024-01-10T15:39:15.898600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Name, Company_Name, Employee_Job_Title, Employee_City, Employee_Country, Employee_Salary, Employment_Status, Employee_Rating]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCNbZCHRPe7q"
   },
   "source": [
    "### 64. Check if any of the columns has NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "id": "4nDFkQI4Pe7q",
    "outputId": "2e8835a7-221e-4c36-adad-dce1c444ee41",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:16.131304Z",
     "start_time": "2024-01-10T15:39:15.996103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                  False\n",
      "Company_Name          False\n",
      "Employee_Job_Title    False\n",
      "Employee_City         False\n",
      "Employee_Country      False\n",
      "Employee_Salary       False\n",
      "Employment_Status     False\n",
      "Employee_Rating       False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG-2nU40Pe7q"
   },
   "source": [
    "### 65. Print the data type of every column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "id": "Mjs07JjUPe7q",
    "outputId": "9143da65-8423-43b4-9d33-aa61a442da10",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:16.151273Z",
     "start_time": "2024-01-10T15:39:16.088677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                   object\n",
      "Company_Name           object\n",
      "Employee_Job_Title     object\n",
      "Employee_City          object\n",
      "Employee_Country       object\n",
      "Employee_Salary       float64\n",
      "Employment_Status      object\n",
      "Employee_Rating       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UqINySMPe7q"
   },
   "source": [
    "### 66. Print the Company_Name column only as a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "id": "zUzEhpEQPe7r",
    "outputId": "6e891dde-7075-45ea-f224-394674513eb0",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:16.299066Z",
     "start_time": "2024-01-10T15:39:16.144347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       James and Sons\n",
      "1                        Nichols-James\n",
      "2                            Scott Inc\n",
      "3         Johnston, Fleming and Tanner\n",
      "4             Baker, Allen and Edwards\n",
      "                      ...             \n",
      "299995                Bullock-Carrillo\n",
      "299996    Johnston, Fleming and Tanner\n",
      "299997                   Nichols-James\n",
      "299998                   Nichols-James\n",
      "299999                  James and Sons\n",
      "Name: Company_Name, Length: 300000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['Company_Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SroDaTjqPe7r"
   },
   "source": [
    "### 67. Print the Company_Name column only as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "id": "bAF-dEwFPe7r",
    "outputId": "173d1877-03ce-4d3d-afcd-0198b32b9e19",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:16.352942Z",
     "start_time": "2024-01-10T15:39:16.299249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Company_Name\n",
      "0                     James and Sons\n",
      "1                      Nichols-James\n",
      "2                          Scott Inc\n",
      "3       Johnston, Fleming and Tanner\n",
      "4           Baker, Allen and Edwards\n",
      "...                              ...\n",
      "299995              Bullock-Carrillo\n",
      "299996  Johnston, Fleming and Tanner\n",
      "299997                 Nichols-James\n",
      "299998                 Nichols-James\n",
      "299999                James and Sons\n",
      "\n",
      "[300000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[['Company_Name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r1AUrqpPe7r"
   },
   "source": [
    "### 68. Select the 'Employee_Job_Title' and 'Employee_City' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "id": "4loNllBJPe7s",
    "outputId": "6fd4ddaa-3fcf-40ef-9383-a99bccab62cc",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:16.421829Z",
     "start_time": "2024-01-10T15:39:16.337532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Employee_Job_Title      Employee_City\n",
      "0                               Equities trader     New Russellton\n",
      "1       Diplomatic Services operational officer  North Melissafurt\n",
      "2                    Regulatory affairs officer           Wardfort\n",
      "3                           Production engineer     West Jamesview\n",
      "4                           Production engineer          Whiteside\n",
      "...                                         ...                ...\n",
      "299995                              Optometrist  North Melissafurt\n",
      "299996                            Administrator         Aliciafort\n",
      "299997                            Administrator   New Cindychester\n",
      "299998                                     Make       Whitakerbury\n",
      "299999                                  Actuary     New Russellton\n",
      "\n",
      "[300000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[['Employee_Job_Title', 'Employee_City']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCpHw5-rPe7s"
   },
   "source": [
    "### 69. Print the number of employees with Employee_Rating greater than the average Employee_Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "id": "9A_4kpmcPe7s",
    "outputId": "a3630f28-722d-4780-d47d-4e11f13ec579",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:16.489916Z",
     "start_time": "2024-01-10T15:39:16.419814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147548\n"
     ]
    }
   ],
   "source": [
    "print(df[df['Employee_Rating'] > df['Employee_Rating'].mean()].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-yMx-0vPe7s"
   },
   "source": [
    "### 74. Print the first 5 rows of the first 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "id": "FfyboFnVPe7t",
    "outputId": "819b7e1f-7722-46aa-a116-424830067bcb",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:16.575838Z",
     "start_time": "2024-01-10T15:39:16.474570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name                  Company_Name  \\\n",
      "0  Spencer Adkins                James and Sons   \n",
      "1    Julie Morton                 Nichols-James   \n",
      "2    Matthew Hall                     Scott Inc   \n",
      "3      Brad Scott  Johnston, Fleming and Tanner   \n",
      "4   Theresa Owens      Baker, Allen and Edwards   \n",
      "\n",
      "                        Employee_Job_Title      Employee_City  \\\n",
      "0                          Equities trader     New Russellton   \n",
      "1  Diplomatic Services operational officer  North Melissafurt   \n",
      "2               Regulatory affairs officer           Wardfort   \n",
      "3                      Production engineer     West Jamesview   \n",
      "4                      Production engineer          Whiteside   \n",
      "\n",
      "        Employee_Country  \n",
      "0  Palestinian Territory  \n",
      "1       Marshall Islands  \n",
      "2               Anguilla  \n",
      "3   Syrian Arab Republic  \n",
      "4               Dominica  \n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlV2l7QZPe7t"
   },
   "source": [
    "### 76. Print the number of employees whose first name starts with the letter 'V'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "id": "RbiShQ15Pe7t",
    "outputId": "f9d4cd0a-68bf-4cdf-b2fd-a69d179752fe",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:16.718924Z",
     "start_time": "2024-01-10T15:39:16.573398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3683\n"
     ]
    }
   ],
   "source": [
    "print(df[df['Name'].str.startswith('V', na=False)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5dya3v-Pe7t"
   },
   "source": [
    "### 77. Print the number of employees whose last name starts with the letter 'R'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "id": "_qKIhg0MPe7t",
    "outputId": "ff575a56-3903-4630-adb6-e1b226b26060",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:17.215382Z",
     "start_time": "2024-01-10T15:39:16.820050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20712\n"
     ]
    }
   ],
   "source": [
    "print(df[df['Name'].str.split().str[-1].str.startswith('R', na=False)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZtSIPM1Pe7u"
   },
   "source": [
    "### 78. Select the rows 2 to 7 and the columns 3 to 7 (both included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "id": "TOb6T1OfPe7u",
    "outputId": "ed8332d8-2aa2-49f7-d3cd-48e9ea64861c",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:17.234993Z",
     "start_time": "2024-01-10T15:39:17.173635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Employee_City      Employee_Country  Employee_Salary Employment_Status\n",
      "2        Wardfort              Anguilla         630890.0         Full Time\n",
      "3  West Jamesview  Syrian Arab Republic         116400.0         Full Time\n",
      "4       Whiteside              Dominica         523499.0         Full Time\n",
      "5    Ricardomouth                  Mali         850140.0         Full Time\n",
      "6        Wardfort                 Aruba         711410.0         Full Time\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[2:7, 3:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syW_Y1NYPe7u"
   },
   "source": [
    "### 79. Select every row after the 10th row and select all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "id": "gQh5Uh6fPe7u",
    "outputId": "7eb7d766-1b66-4ada-b8fc-be18187cc619",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:17.239521Z",
     "start_time": "2024-01-10T15:39:17.177557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name                    Company_Name  \\\n",
      "10      Victoria Sutton         White, Mcclain and Cobb   \n",
      "11      Timothy Johnson        Baker, Allen and Edwards   \n",
      "12       Tiffany Galvan  Campos, Reynolds and Mccormick   \n",
      "13          David Duran                   Nichols-James   \n",
      "14           Julie Cook                    Matthews Inc   \n",
      "...                 ...                             ...   \n",
      "299995       Nancy Neal                Bullock-Carrillo   \n",
      "299996   Michele Butler    Johnston, Fleming and Tanner   \n",
      "299997      Lynn Wilson                   Nichols-James   \n",
      "299998    Lindsey Keith                   Nichols-James   \n",
      "299999    Karen Delgado                  James and Sons   \n",
      "\n",
      "                             Employee_Job_Title      Employee_City  \\\n",
      "10                              Naval architect          Whiteside   \n",
      "11                   Regulatory affairs officer       Ricardomouth   \n",
      "12      Diplomatic Services operational officer     West Jamesview   \n",
      "13                 Investment banker, corporate     New Russellton   \n",
      "14                              Equities trader     New Russellton   \n",
      "...                                         ...                ...   \n",
      "299995                              Optometrist  North Melissafurt   \n",
      "299996                            Administrator         Aliciafort   \n",
      "299997                            Administrator   New Cindychester   \n",
      "299998                                     Make       Whitakerbury   \n",
      "299999                                  Actuary     New Russellton   \n",
      "\n",
      "       Employee_Country  Employee_Salary Employment_Status  Employee_Rating  \n",
      "10               Poland         656260.0         Full Time              4.9  \n",
      "11              Georgia         503610.0         Full Time              2.9  \n",
      "12                Niger         786430.0            Intern              3.6  \n",
      "13              Georgia         910210.0         Full Time              4.9  \n",
      "14          Puerto Rico         328860.0         Full Time              4.8  \n",
      "...                 ...              ...               ...              ...  \n",
      "299995            Samoa          99670.0            Intern              3.3  \n",
      "299996             Cuba         949580.0            Intern              2.6  \n",
      "299997          Bolivia         802830.0         Full Time              0.6  \n",
      "299998   Western Sahara         257240.0         Full Time              2.4  \n",
      "299999   United Kingdom         575770.0            Intern              3.3  \n",
      "\n",
      "[299990 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[10:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hwy-ERDPe7v"
   },
   "source": [
    "### 83. Print the name of the company with the maximum employees having rating > 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "id": "NsA3RrBfPe7v",
    "outputId": "7327d64e-3cc0-47e8-c5c6-62549879e853",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:17.254659Z",
     "start_time": "2024-01-10T15:39:17.180430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Inc\n"
     ]
    }
   ],
   "source": [
    "employees = df[df['Employee_Rating'] > 4]\n",
    "\n",
    "employee_count = employees.groupby('Company_Name').size()\n",
    "\n",
    "print(employee_count.idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKgaAnx4Pe7v"
   },
   "source": [
    "### 88. Which is the most common first name in the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "id": "QqECvk_hPe7v",
    "outputId": "cabb2a23-39e8-4596-ef66-96d78f18076f",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:17.591040Z",
     "start_time": "2024-01-10T15:39:17.201432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael\n"
     ]
    }
   ],
   "source": [
    "df['first_name'] = df['Name'].str.split().str[0]\n",
    "\n",
    "print(df['first_name'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNkCgUBPPe7w"
   },
   "source": [
    "### 90. What is the average name length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "id": "p8FEbitWPe7w",
    "outputId": "36196b79-5f95-46e0-a992-9d01d5bd885d",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:17.654221Z",
     "start_time": "2024-01-10T15:39:17.528557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.1079\n"
     ]
    }
   ],
   "source": [
    "df['name_len'] = df['Name'].apply(len)\n",
    "\n",
    "print(df['name_len'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcXYo3iCPe7w"
   },
   "source": [
    "# Pandas Notebook 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "id": "FcTcKEiNPe7w",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:17.674828Z",
     "start_time": "2024-01-10T15:39:17.569469Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "id": "6y8q-7ecPe7x",
    "outputId": "f22f68aa-0b8f-4778-bfb1-f902f48f37f5",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:17.891910Z",
     "start_time": "2024-01-10T15:39:17.571514Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input_data/employee_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uwpv8QQPe7x"
   },
   "source": [
    "### 91. What is the ratio of total full-time employees to Interns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "id": "VlHgfIl8Pe7x",
    "outputId": "6a5d720a-8725-478d-afa3-f8d113729082",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:17.997620Z",
     "start_time": "2024-01-10T15:39:17.822842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0008334722453744\n"
     ]
    }
   ],
   "source": [
    "full_time = df[df['Employment_Status'] == 'Full Time'].shape[0]\n",
    "intern = df[df['Employment_Status'] == 'Intern'].shape[0]\n",
    "print(full_time / intern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_ZnTPK2Pe7x"
   },
   "source": [
    "### 92. Starting from the first record, print every third record in the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmL3VdqYPe7y"
   },
   "source": [
    "Print 1st row, then 4th, 7th, 10th, and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "id": "zetfxJSbPe7y",
    "outputId": "1c4417f4-a410-4eae-ef37-4fed904ff2c8",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.001983Z",
     "start_time": "2024-01-10T15:39:17.860147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Name                    Company_Name  \\\n",
      "0          Spencer Adkins                  James and Sons   \n",
      "3              Brad Scott    Johnston, Fleming and Tanner   \n",
      "6             Kelly Brown                     Andrade LLC   \n",
      "9         Michael Edwards  Campos, Reynolds and Mccormick   \n",
      "12         Tiffany Galvan  Campos, Reynolds and Mccormick   \n",
      "...                   ...                             ...   \n",
      "299985      Chase Stevens                       Nelson-Li   \n",
      "299988     Kenneth Hurley                       Scott Inc   \n",
      "299991  William Rodriguez                       Scott Inc   \n",
      "299994      Kelly Bennett         White, Mcclain and Cobb   \n",
      "299997        Lynn Wilson                   Nichols-James   \n",
      "\n",
      "                             Employee_Job_Title     Employee_City  \\\n",
      "0                               Equities trader    New Russellton   \n",
      "3                           Production engineer    West Jamesview   \n",
      "6                               Naval architect          Wardfort   \n",
      "9                                    Ergonomist  New Cindychester   \n",
      "12      Diplomatic Services operational officer    West Jamesview   \n",
      "...                                         ...               ...   \n",
      "299985                           Energy manager      Whitakerbury   \n",
      "299988                                     Make    New Russellton   \n",
      "299991                               Ergonomist         Whiteside   \n",
      "299994                Radiographer, therapeutic          Wardfort   \n",
      "299997                            Administrator  New Cindychester   \n",
      "\n",
      "                        Employee_Country  Employee_Salary Employment_Status  \\\n",
      "0                  Palestinian Territory           321520         Full Time   \n",
      "3                   Syrian Arab Republic           116400         Full Time   \n",
      "6                                  Aruba           711410         Full Time   \n",
      "9       Lao People's Democratic Republic           516950         Full Time   \n",
      "12                                 Niger           786430            Intern   \n",
      "...                                  ...              ...               ...   \n",
      "299985          Northern Mariana Islands           590590         Full Time   \n",
      "299988                Russian Federation           211180         Full Time   \n",
      "299991                       New Zealand           214400         Full Time   \n",
      "299994                              Fiji           182270         Full Time   \n",
      "299997                           Bolivia           802830         Full Time   \n",
      "\n",
      "        Employee_Rating  \n",
      "0                   3.9  \n",
      "3                   3.1  \n",
      "6                   2.0  \n",
      "9                   2.3  \n",
      "12                  3.6  \n",
      "...                 ...  \n",
      "299985              2.6  \n",
      "299988              3.9  \n",
      "299991              1.5  \n",
      "299994              3.6  \n",
      "299997              0.6  \n",
      "\n",
      "[100000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[::3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEIHS5YzPe7y"
   },
   "source": [
    "### 93. Find the average salary for every company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "id": "vXDyK9zpPe7y",
    "outputId": "c1ccfcb2-5cc7-4e3a-c50b-7feb03b4a943",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.042543Z",
     "start_time": "2024-01-10T15:39:17.867495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company_Name\n",
      "Andrade LLC                       497237.159385\n",
      "Baker, Allen and Edwards          498032.358445\n",
      "Bullock-Carrillo                  499603.804865\n",
      "Campos, Reynolds and Mccormick    503528.982687\n",
      "James and Sons                    503581.015754\n",
      "Johnston, Fleming and Tanner      500579.128010\n",
      "Marshall-Holloway                 502314.169445\n",
      "Matthews Inc                      501640.159488\n",
      "Nelson-Li                         500569.824558\n",
      "Nichols-James                     497881.232334\n",
      "Scott Inc                         500491.809024\n",
      "Taylor-Ramos                      498747.292516\n",
      "Thomas-Spencer                    499350.850164\n",
      "Wallace, Smith and Shepard        500807.608810\n",
      "White, Mcclain and Cobb           499083.493806\n",
      "Name: Employee_Salary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('Company_Name')['Employee_Salary'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JDfHAIIPe7y"
   },
   "source": [
    "### 95. Find the average salary and average rating for every company in a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "id": "Nrg4uySPPe7z",
    "outputId": "c5436c1d-9f1d-4726-fd29-17b6d4a32f00",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.063713Z",
     "start_time": "2024-01-10T15:39:17.894912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Employee_Salary  Employee_Rating\n",
      "Company_Name                                                    \n",
      "Andrade LLC                       497237.159385         2.498218\n",
      "Baker, Allen and Edwards          498032.358445         2.504795\n",
      "Bullock-Carrillo                  499603.804865         2.502014\n",
      "Campos, Reynolds and Mccormick    503528.982687         2.506288\n",
      "James and Sons                    503581.015754         2.505023\n",
      "Johnston, Fleming and Tanner      500579.128010         2.513159\n",
      "Marshall-Holloway                 502314.169445         2.504900\n",
      "Matthews Inc                      501640.159488         2.525454\n",
      "Nelson-Li                         500569.824558         2.504649\n",
      "Nichols-James                     497881.232334         2.488554\n",
      "Scott Inc                         500491.809024         2.515993\n",
      "Taylor-Ramos                      498747.292516         2.513150\n",
      "Thomas-Spencer                    499350.850164         2.505114\n",
      "Wallace, Smith and Shepard        500807.608810         2.497402\n",
      "White, Mcclain and Cobb           499083.493806         2.504047\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('Company_Name').agg({'Employee_Salary': 'mean', 'Employee_Rating': 'mean'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2VHx3CnPe7z"
   },
   "source": [
    "### 96. Find the number of unique Employee_City corresponding to every Company_Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "id": "XgsJfd2jPe7z",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.212742Z",
     "start_time": "2024-01-10T15:39:17.912840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company_Name\n",
      "Andrade LLC                       10\n",
      "Baker, Allen and Edwards          10\n",
      "Bullock-Carrillo                  10\n",
      "Campos, Reynolds and Mccormick    10\n",
      "James and Sons                    10\n",
      "Johnston, Fleming and Tanner      10\n",
      "Marshall-Holloway                 10\n",
      "Matthews Inc                      10\n",
      "Nelson-Li                         10\n",
      "Nichols-James                     10\n",
      "Scott Inc                         10\n",
      "Taylor-Ramos                      10\n",
      "Thomas-Spencer                    10\n",
      "Wallace, Smith and Shepard        10\n",
      "White, Mcclain and Cobb           10\n",
      "Name: Employee_City, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('Company_Name')['Employee_City'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VvbGXqlPe70"
   },
   "source": [
    "### 98. Print the number of full-time and intern employees for every company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "id": "Gln5msczPe70",
    "outputId": "253b73aa-c578-4c89-f935-33689adbce10",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.266688Z",
     "start_time": "2024-01-10T15:39:17.988656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company_Name                    Employment_Status\n",
      "Andrade LLC                     Full Time            15964\n",
      "                                Intern                4019\n",
      "Baker, Allen and Edwards        Full Time            16118\n",
      "                                Intern                3966\n",
      "Bullock-Carrillo                Full Time            16135\n",
      "                                Intern                3928\n",
      "Campos, Reynolds and Mccormick  Full Time            15930\n",
      "                                Intern                3997\n",
      "James and Sons                  Full Time            15888\n",
      "                                Intern                3980\n",
      "Johnston, Fleming and Tanner    Full Time            15832\n",
      "                                Intern                3979\n",
      "Marshall-Holloway               Full Time            15871\n",
      "                                Intern                3988\n",
      "Matthews Inc                    Full Time            16082\n",
      "                                Intern                4001\n",
      "Nelson-Li                       Full Time            16027\n",
      "                                Intern                4105\n",
      "Nichols-James                   Full Time            15872\n",
      "                                Intern                4039\n",
      "Scott Inc                       Full Time            16396\n",
      "                                Intern                3994\n",
      "Taylor-Ramos                    Full Time            16086\n",
      "                                Intern                4036\n",
      "Thomas-Spencer                  Full Time            16037\n",
      "                                Intern                4105\n",
      "Wallace, Smith and Shepard      Full Time            15467\n",
      "                                Intern                3897\n",
      "White, Mcclain and Cobb         Full Time            16305\n",
      "                                Intern                3956\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['Company_Name', 'Employment_Status']).count()['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngQliglUPe70"
   },
   "source": [
    "### 99. Print the job title with the most employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "id": "zKOcaxGhPe70",
    "outputId": "e4bcfa80-e62e-4ea5-93f2-c0ef98b3b8b3",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.323039Z",
     "start_time": "2024-01-10T15:39:18.052014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diplomatic Services operational officer\n"
     ]
    }
   ],
   "source": [
    "print(df['Employee_Job_Title'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa-4WcqRPe70"
   },
   "source": [
    "### 107. Check if the substring 'Michael Edward' appears in the Name column or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "id": "-Z4xky-rPe71",
    "outputId": "a7c7147c-ad27-4ccd-e7c6-a4fbbaaa4100",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.356329Z",
     "start_time": "2024-01-10T15:39:18.065707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name                    Company_Name  \\\n",
      "9       Michael Edwards  Campos, Reynolds and Mccormick   \n",
      "5255    Michael Edwards    Johnston, Fleming and Tanner   \n",
      "18849   Michael Edwards         White, Mcclain and Cobb   \n",
      "25616   Michael Edwards                Bullock-Carrillo   \n",
      "31519   Michael Edwards                       Nelson-Li   \n",
      "112668  Michael Edwards                       Scott Inc   \n",
      "114386  Michael Edwards                   Nichols-James   \n",
      "124065  Michael Edwards         White, Mcclain and Cobb   \n",
      "135078  Michael Edwards                    Matthews Inc   \n",
      "149363  Michael Edwards                       Scott Inc   \n",
      "158104  Michael Edwards      Wallace, Smith and Shepard   \n",
      "191831  Michael Edwards      Wallace, Smith and Shepard   \n",
      "193911  Michael Edwards        Baker, Allen and Edwards   \n",
      "205550  Michael Edwards    Johnston, Fleming and Tanner   \n",
      "210504  Michael Edwards         White, Mcclain and Cobb   \n",
      "217498  Michael Edwards    Johnston, Fleming and Tanner   \n",
      "217970  Michael Edwards                Bullock-Carrillo   \n",
      "227767  Michael Edwards               Marshall-Holloway   \n",
      "229786  Michael Edwards                       Scott Inc   \n",
      "267189  Michael Edwards                  James and Sons   \n",
      "276731  Michael Edwards  Campos, Reynolds and Mccormick   \n",
      "282601  Michael Edwards         White, Mcclain and Cobb   \n",
      "287887  Michael Edwards                       Scott Inc   \n",
      "298857  Michael Edwards         White, Mcclain and Cobb   \n",
      "\n",
      "                                       Employee_Job_Title      Employee_City  \\\n",
      "9                                              Ergonomist   New Cindychester   \n",
      "5255                           Regulatory affairs officer     West Jamesview   \n",
      "18849   Armed forces logistics/support/administrative ...          Whiteside   \n",
      "25616                           Trading standards officer           Wardfort   \n",
      "31519                                     Patent examiner          Whiteside   \n",
      "112668                                    Equities trader     West Jamesview   \n",
      "114386                                    Patent examiner       Whitakerbury   \n",
      "124065            Diplomatic Services operational officer       Ricardomouth   \n",
      "135078                                    Patent examiner           Wardfort   \n",
      "149363            Diplomatic Services operational officer           Wardfort   \n",
      "158104                         Regulatory affairs officer     New Russellton   \n",
      "191831                          Trading standards officer         Aliciafort   \n",
      "193911                       Investment banker, corporate   New Cindychester   \n",
      "205550                                    Patent examiner           Wardfort   \n",
      "210504                                         Ergonomist          Whiteside   \n",
      "217498                                            Actuary           Wardfort   \n",
      "217970                                    Equities trader     West Jamesview   \n",
      "227767  Armed forces logistics/support/administrative ...  North Melissafurt   \n",
      "229786            Diplomatic Services operational officer       Whitakerbury   \n",
      "267189                                               Make       Ricardomouth   \n",
      "276731  Armed forces logistics/support/administrative ...  North Melissafurt   \n",
      "282601                                    Naval architect           Wardfort   \n",
      "287887                       Investment banker, corporate         Aliciafort   \n",
      "298857                                               Make   New Cindychester   \n",
      "\n",
      "                        Employee_Country  Employee_Salary Employment_Status  \\\n",
      "9       Lao People's Democratic Republic           516950         Full Time   \n",
      "5255                              Brazil           822420            Intern   \n",
      "18849                            Croatia           818710         Full Time   \n",
      "25616                          Greenland           467160            Intern   \n",
      "31519                             Kuwait           287350         Full Time   \n",
      "112668          Northern Mariana Islands            21540         Full Time   \n",
      "114386                           Iceland           687630            Intern   \n",
      "124065          Central African Republic           546870         Full Time   \n",
      "135078                           Grenada           209030         Full Time   \n",
      "149363                             Chile           254160            Intern   \n",
      "158104                            Angola           121770         Full Time   \n",
      "191831                            Israel           854420         Full Time   \n",
      "193911                           Lesotho           365180         Full Time   \n",
      "205550                           Belgium           579130            Intern   \n",
      "210504                       Philippines           150730         Full Time   \n",
      "217498               Trinidad and Tobago           600090         Full Time   \n",
      "217970        Slovakia (Slovak Republic)           698220         Full Time   \n",
      "227767                             Ghana           565940            Intern   \n",
      "229786          Turks and Caicos Islands           105450            Intern   \n",
      "267189                          Paraguay           391700            Intern   \n",
      "276731                            Serbia           865280            Intern   \n",
      "282601                          Cambodia           855180            Intern   \n",
      "287887                            Belize            69680            Intern   \n",
      "298857                             Macao           318800         Full Time   \n",
      "\n",
      "        Employee_Rating  \n",
      "9                   2.3  \n",
      "5255                3.5  \n",
      "18849               2.8  \n",
      "25616               2.1  \n",
      "31519               1.8  \n",
      "112668              1.5  \n",
      "114386              2.1  \n",
      "124065              1.4  \n",
      "135078              2.2  \n",
      "149363              1.2  \n",
      "158104              1.1  \n",
      "191831              4.8  \n",
      "193911              1.8  \n",
      "205550              4.7  \n",
      "210504              3.2  \n",
      "217498              0.8  \n",
      "217970              0.7  \n",
      "227767              4.4  \n",
      "229786              2.6  \n",
      "267189              1.4  \n",
      "276731              0.7  \n",
      "282601              4.7  \n",
      "287887              1.9  \n",
      "298857              3.6  \n"
     ]
    }
   ],
   "source": [
    "print(df[df['Name'].str.contains('Michael Edward')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFvkiETQPe71"
   },
   "source": [
    "### 110. Print the number of records whose company name contains the substring 'LL' (case-insensitive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "id": "N3o9cFLRPe71",
    "outputId": "e0081780-c51c-4163-9198-13dd385a43fb",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.478178Z",
     "start_time": "2024-01-10T15:39:18.120771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99353\n"
     ]
    }
   ],
   "source": [
    "print(df[df['Company_Name'].str.contains('LL', case=False)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZP6lYrDPe71"
   },
   "source": [
    "### 111. Select the first row corresponding to every company in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "id": "rXcmTisoPe71",
    "outputId": "d7a3e88f-c294-4db1-989b-a2cae47526fc",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.508774Z",
     "start_time": "2024-01-10T15:39:18.202493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Name  \\\n",
      "Company_Name                                         \n",
      "Andrade LLC                          Vanessa Allen   \n",
      "Baker, Allen and Edwards             Theresa Owens   \n",
      "Bullock-Carrillo                      Carrie Woods   \n",
      "Campos, Reynolds and Mccormick     Michael Edwards   \n",
      "James and Sons                      Spencer Adkins   \n",
      "Johnston, Fleming and Tanner            Brad Scott   \n",
      "Marshall-Holloway                   David Phillips   \n",
      "Matthews Inc                           Vicki Beard   \n",
      "Nelson-Li                       Micheal Fitzgerald   \n",
      "Nichols-James                         Julie Morton   \n",
      "Scott Inc                             Matthew Hall   \n",
      "Taylor-Ramos                           Lisa French   \n",
      "Thomas-Spencer                           Gail Rose   \n",
      "Wallace, Smith and Shepard            Ronald Clark   \n",
      "White, Mcclain and Cobb            Victoria Sutton   \n",
      "\n",
      "                                                     Employee_Job_Title  \\\n",
      "Company_Name                                                              \n",
      "Andrade LLC                                                        Make   \n",
      "Baker, Allen and Edwards                            Production engineer   \n",
      "Bullock-Carrillo                                             Ergonomist   \n",
      "Campos, Reynolds and Mccormick                               Ergonomist   \n",
      "James and Sons                                          Equities trader   \n",
      "Johnston, Fleming and Tanner                        Production engineer   \n",
      "Marshall-Holloway                             Radiographer, therapeutic   \n",
      "Matthews Inc                    Diplomatic Services operational officer   \n",
      "Nelson-Li                       Diplomatic Services operational officer   \n",
      "Nichols-James                   Diplomatic Services operational officer   \n",
      "Scott Inc                                    Regulatory affairs officer   \n",
      "Taylor-Ramos                                  Radiographer, therapeutic   \n",
      "Thomas-Spencer                                          Patent examiner   \n",
      "Wallace, Smith and Shepard                   Regulatory affairs officer   \n",
      "White, Mcclain and Cobb                                 Naval architect   \n",
      "\n",
      "                                    Employee_City  \\\n",
      "Company_Name                                        \n",
      "Andrade LLC                          Ricardomouth   \n",
      "Baker, Allen and Edwards                Whiteside   \n",
      "Bullock-Carrillo                   New Russellton   \n",
      "Campos, Reynolds and Mccormick   New Cindychester   \n",
      "James and Sons                     New Russellton   \n",
      "Johnston, Fleming and Tanner       West Jamesview   \n",
      "Marshall-Holloway                     Kristaburgh   \n",
      "Matthews Inc                          Kristaburgh   \n",
      "Nelson-Li                            Whitakerbury   \n",
      "Nichols-James                   North Melissafurt   \n",
      "Scott Inc                                Wardfort   \n",
      "Taylor-Ramos                       West Jamesview   \n",
      "Thomas-Spencer                       Whitakerbury   \n",
      "Wallace, Smith and Shepard      North Melissafurt   \n",
      "White, Mcclain and Cobb                 Whiteside   \n",
      "\n",
      "                                                Employee_Country  \\\n",
      "Company_Name                                                       \n",
      "Andrade LLC                                                 Mali   \n",
      "Baker, Allen and Edwards                                Dominica   \n",
      "Bullock-Carrillo                                           Gabon   \n",
      "Campos, Reynolds and Mccormick  Lao People's Democratic Republic   \n",
      "James and Sons                             Palestinian Territory   \n",
      "Johnston, Fleming and Tanner                Syrian Arab Republic   \n",
      "Marshall-Holloway                         British Virgin Islands   \n",
      "Matthews Inc                                      Western Sahara   \n",
      "Nelson-Li                                            Switzerland   \n",
      "Nichols-James                                   Marshall Islands   \n",
      "Scott Inc                                               Anguilla   \n",
      "Taylor-Ramos                                              Kuwait   \n",
      "Thomas-Spencer                                           Finland   \n",
      "Wallace, Smith and Shepard                                 Palau   \n",
      "White, Mcclain and Cobb                                   Poland   \n",
      "\n",
      "                                Employee_Salary Employment_Status  \\\n",
      "Company_Name                                                        \n",
      "Andrade LLC                              850140         Full Time   \n",
      "Baker, Allen and Edwards                 523499         Full Time   \n",
      "Bullock-Carrillo                         985290         Full Time   \n",
      "Campos, Reynolds and Mccormick           516950         Full Time   \n",
      "James and Sons                           321520         Full Time   \n",
      "Johnston, Fleming and Tanner             116400         Full Time   \n",
      "Marshall-Holloway                         58800         Full Time   \n",
      "Matthews Inc                             777000         Full Time   \n",
      "Nelson-Li                                796690         Full Time   \n",
      "Nichols-James                            589090         Full Time   \n",
      "Scott Inc                                630890         Full Time   \n",
      "Taylor-Ramos                             870580         Full Time   \n",
      "Thomas-Spencer                           178570         Full Time   \n",
      "Wallace, Smith and Shepard               914110         Full Time   \n",
      "White, Mcclain and Cobb                  656260         Full Time   \n",
      "\n",
      "                                Employee_Rating  \n",
      "Company_Name                                     \n",
      "Andrade LLC                                 2.6  \n",
      "Baker, Allen and Edwards                    4.8  \n",
      "Bullock-Carrillo                            2.4  \n",
      "Campos, Reynolds and Mccormick              2.3  \n",
      "James and Sons                              3.9  \n",
      "Johnston, Fleming and Tanner                3.1  \n",
      "Marshall-Holloway                           0.6  \n",
      "Matthews Inc                                3.3  \n",
      "Nelson-Li                                   4.1  \n",
      "Nichols-James                               4.3  \n",
      "Scott Inc                                   3.1  \n",
      "Taylor-Ramos                                1.3  \n",
      "Thomas-Spencer                              1.9  \n",
      "Wallace, Smith and Shepard                  3.2  \n",
      "White, Mcclain and Cobb                     4.9  \n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('Company_Name').first())\n",
    "\n",
    "#first(), last(), nth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8QP7Vo5Pe72"
   },
   "source": [
    "### 113. Reset the index of the dataframe inplace and delete the older index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "id": "pd4HD_60Pe72",
    "outputId": "09594bed-d803-43e5-e9b1-bedbe852baf8",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.549608Z",
     "start_time": "2024-01-10T15:39:18.287484Z"
    }
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6hjV2BpPe72"
   },
   "source": [
    "### 115-1) Add a new row at the bottom of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "id": "24Sd0u3TPe72",
    "outputId": "902695c8-84eb-4ed8-85a0-5a87ccc363a7",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.758617Z",
     "start_time": "2024-01-10T15:39:18.547529Z"
    }
   },
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame([['Kelly Brown',\t'Andrade LLC', 'Naval architect', 'Wardfort', 'Aruba', 711410, 'Full Time', 2.0]], columns=df.columns)\n",
    "df = pd.concat([df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMmbfUv9Pe73"
   },
   "source": [
    "### 115-2) Delete the row that was just newly added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "id": "TLQxXlx0Pe73",
    "outputId": "9adec665-a7d6-41f2-a3a2-80e064ec369b",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.840600Z",
     "start_time": "2024-01-10T15:39:18.741360Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(df.index[-1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j397D96QPe73"
   },
   "source": [
    "### 117. Add a new column \"Employee_Rating_New\" which should be as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCmW_CxrPe73"
   },
   "source": [
    "Employee_Rating_New = max(1.5, 2*Employee_Rating - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "id": "HabxS2nEPe73",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:18.909786Z",
     "start_time": "2024-01-10T15:39:18.783304Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Employee_Rating_New'] = df['Employee_Rating'].apply(lambda x: max(1.5, 2 * x - 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDBjDQmZPe74"
   },
   "source": [
    "### 118. Convert the entire DataFrame to a list of lists. Do NOT overwrite to the current dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "id": "1gQNp9XxPe74",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:56.481786Z",
     "start_time": "2024-01-10T15:39:56.397206Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_Lists = df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VX4apTHYPe74"
   },
   "source": [
    "### 120. Rearrange the columns in the below order. Overwrite to the current DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "id": "GiSuCB1pPe74",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:19.962783Z",
     "start_time": "2024-01-10T15:39:19.925056Z"
    }
   },
   "outputs": [],
   "source": [
    "new_order = [\"Name\", \"Employee_Job_Title\", \"Company_Name\",\n",
    "             \"Employee_City\", \"Employee_Country\", \"Employment_Status\",\n",
    "             \"Employee_Salary\", \"Employee_Rating\", \"Employee_Rating_New\"]\n",
    "\n",
    "df = df[new_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zeaEu2DPe74"
   },
   "source": [
    "### 123. Drop the 'Name' column inplace from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "id": "7RQLt4ARPe75",
    "outputId": "69b04cfa-2c3b-43c8-e0a9-2b433b0a25bd",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:19.962901Z",
     "start_time": "2024-01-10T15:39:19.927094Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myepx0x9Pe75"
   },
   "source": [
    "### 126. Rename the columns and store to a new DataFrame 'df_renamed':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deGE3auXPe75"
   },
   "source": [
    "1. Employee_Rating -> Rating\n",
    "2. Employee_Country -> Country\n",
    "3. Employee_Salary -> Salary\n",
    "4. Employee_Rating_New -> Rating_New\n",
    "5. Employment_Status -> Employment_type\n",
    "6. Employment_City -> City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "id": "eK9nSJiHPe75",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:19.979957Z",
     "start_time": "2024-01-10T15:39:19.928378Z"
    }
   },
   "outputs": [],
   "source": [
    "df_renamed = df.rename(columns={\n",
    "    'Employee_Rating': 'Rating',\n",
    "    'Employee_Country': 'Country',\n",
    "    'Employee_Salary': 'Salary',\n",
    "    'Employee_Rating_New': 'Rating_New',\n",
    "    'Employment_Status': 'Employment_type',\n",
    "    'Employment_City': 'City'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhM7zYBePe76"
   },
   "source": [
    "### 128. Count the number of NaN values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "id": "-OIBONVHPe76",
    "outputId": "e4f48e31-faf5-43ad-cce0-40078b3c8598",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:19.980065Z",
     "start_time": "2024-01-10T15:39:19.929540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee_Job_Title     0\n",
      "Company_Name           0\n",
      "Employee_City          0\n",
      "Employee_Country       0\n",
      "Employment_Status      0\n",
      "Employee_Salary        0\n",
      "Employee_Rating        0\n",
      "Employee_Rating_New    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mmwv-BkePe76"
   },
   "source": [
    "### 131.  Map every Company_Name to a unique integer value. Name the new column \"Company_ID\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOk--optPe76"
   },
   "source": [
    "For instance, if the data has 5 companies, \"Company A\" -> 1, \"Company B\" -> 2, \"Company C\" -> 3, \"Company D\" -> 4, \"Company E\" -> 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "id": "AaoXRKB_Pe77",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:19.980118Z",
     "start_time": "2024-01-10T15:39:19.931355Z"
    }
   },
   "outputs": [],
   "source": [
    "company_name_mapping = {company: idx for idx, company in enumerate(df['Company_Name'].unique())}\n",
    "df['Company_ID'] = df['Company_Name'].map(company_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgXvWQrsPe77"
   },
   "source": [
    "### 133. Print the number of rows where 'City' belongs to the following list of cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfLlVniSPe77"
   },
   "source": [
    "Use the isin() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "id": "Z7hJfEGoPe77",
    "outputId": "1de1f4e0-cb9e-4271-a69b-d9abb9bd98d7",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:19.980168Z",
     "start_time": "2024-01-10T15:39:19.932599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90054\n"
     ]
    }
   ],
   "source": [
    "city_filter_list = [\"New Russellton\", \"Whiteside\", \"Kristaburgh\"]\n",
    "\n",
    "row_count = len(df[df['Employee_City'].isin(city_filter_list)])\n",
    "print(row_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWaTfVdzPe77"
   },
   "source": [
    "### 135. Print the name of the person with the 10th largest salary. If there are multiple people with the same salary, print all names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "id": "nf_k7gPOPe78",
    "outputId": "f2adfc10-959c-4d43-ce8b-02390212e423",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:20.390050Z",
     "start_time": "2024-01-10T15:39:19.933896Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Name'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3652\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3651\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3652\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[518], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m sorted_df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39msort_values(by\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEmployee_Salary\u001B[39m\u001B[38;5;124m'\u001B[39m, ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m tenth_largest_salary \u001B[38;5;241m=\u001B[39m sorted_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEmployee_Salary\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique()[\u001B[38;5;241m9\u001B[39m]\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43msorted_df\u001B[49m\u001B[43m[\u001B[49m\u001B[43msorted_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mEmployee_Salary\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtenth_largest_salary\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mName\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mtolist())\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3761\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3763\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3654\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3652\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3654\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3655\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3656\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3657\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3658\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3659\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Name'"
     ]
    }
   ],
   "source": [
    "sorted_df = df.sort_values(by='Employee_Salary', ascending=False)\n",
    "\n",
    "tenth_largest_salary = sorted_df['Employee_Salary'].unique()[9]\n",
    "print(sorted_df[sorted_df['Employee_Salary'] == tenth_largest_salary]['Name'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBkKlLHIPe78"
   },
   "source": [
    "### 136. Print a cross tabulation of Company Name and Employment Type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRkwdkPbPe78",
    "outputId": "c40423eb-c86d-47f3-d5e3-e548063e5744",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.967129Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pd.crosstab(df['Company_Name'], df['Employment_Status']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrM0r91NPe78"
   },
   "source": [
    "### 143-145. Print the 25th, 50th and 75th percentile of the Salary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljZc-1O1Pe78",
    "outputId": "44bd1fcc-a6a6-4981-b699-059ad38091c2",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.968453Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.percentile(df['Employee_Salary'], [25, 50, 75]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TL8a8tUPe79"
   },
   "source": [
    "### 147. Distribute the Salary column in 10 equal sized bins and label each bin from 1 to 10 and add a new column named \"Labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrbC-VNUPe79",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.969502Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Labels'] = pd.cut(df['Employee_Salary'], bins=10, labels=range(1, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVe6rP-kPe79"
   },
   "source": [
    "# Pandas Notebook 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0Wbl2GQPe79"
   },
   "source": [
    "### 151. Sort DataFrame based on another list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBIbQltKPe79",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.970692Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVMuIqR4Pe79",
    "outputId": "82b19342-c2dc-4c82-d8ae-0939b39a4f30",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.972095Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
    "                   [\"C\", 3], [\"D\", 4]], columns=[\"col1\", \"col2\"])\n",
    "\n",
    "sort_list = [\"C\", \"A\", \"D\", \"B\"]\n",
    "\n",
    "# start your code below\n",
    "new_df = df.sort_values(by='col1', key=lambda x: x.map({value: idx for idx, value in enumerate(sort_list)}))\n",
    "# end your code here\n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOMXwrxgPe7-"
   },
   "source": [
    "### 152. Insert a column at a specific location in a DataFrame with a name, \"new_column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XByXiC12Pe7-",
    "outputId": "63b744c4-3f5b-4512-fb3f-5514f91368ad",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.973334Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
    "                   [\"C\", 3], [\"D\", 4]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "new_column = [\"P\", \"Q\", \"R\", \"S\"]\n",
    "insert_position = 1 ## between col_A and col_B\n",
    "\n",
    "## start your code below\n",
    "df.insert(loc=insert_position, column='new_column', value=new_column)\n",
    "\n",
    "## end your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3shGNnyzPe7-"
   },
   "source": [
    "### 154. Count the number of Non-NaN cells for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHuyZYDUPe7-",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.974497Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWws51PzPe7_",
    "outputId": "108b534a-f139-40e2-dc35-e3adfa47223f",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.975621Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", np.NaN], [np.NaN, 2],\n",
    "                   [\"C\", np.NaN], [\"D\", 4]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "## start your code below\n",
    "print(df.count())\n",
    "## end your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJLDTWytPe7_"
   },
   "source": [
    "### 156. Reverse DataFrame row-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dp5oaekgPe7_",
    "outputId": "588e4ae2-8605-4960-fe63-d4fb7f8db47a",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.976737Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
    "                   [\"C\", 3], [\"D\", 4]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "## start your code below\n",
    "df_reversed = df[::-1]\n",
    "## end our code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pU4_yh9QPe7_"
   },
   "source": [
    "### 157. Reverse DataFrame column-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1zbUlyuPe8A",
    "outputId": "0805cb05-18bd-4420-8480-c68c0a963b96",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.977866Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
    "                   [\"C\", 3], [\"D\", 4]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "## start your code below\n",
    "df_reversed = df.iloc[:, ::-1]\n",
    "## end your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5OmWLAaPe8A"
   },
   "source": [
    "### 158. Insert a row at an arbitrary position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpBYs6BaPe8A",
    "outputId": "597b3b56-a302-4c80-95f5-77d83b71cc8c",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.978906Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
    "                   [\"C\", 3], [\"D\", 4]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "insert_pos = 1\n",
    "insert_row = [\"P\", 5]\n",
    "\n",
    "## start your code below\n",
    "df = pd.concat([df.iloc[:insert_pos], pd.DataFrame([insert_row], columns=df.columns), df.iloc[insert_pos:]], ignore_index=True)\n",
    "## end your code here\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qrE1LqlPe8A"
   },
   "source": [
    "### 160. The cumulative sum of a column in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQrSlracPe8B",
    "outputId": "888a1281-5eac-465f-e72d-473bb8d0dfe7",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.979678Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
    "                   [\"C\", 3], [\"D\", 4]], columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "## start your code below\n",
    "df[\"col_A\" + '_cumsum'] = df['col_A'].cumsum()\n",
    "df[\"col_B\" + '_cumsum'] = df['col_B'].cumsum()\n",
    "## end your code here\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFw8wRDDPe8B"
   },
   "source": [
    "### 165. Filter n-largest values from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUN5ZeDnPe8B",
    "outputId": "356b0ffb-b6cd-4819-b6b9-828f823ca190",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.980437Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", 200], [\"B\", 400],\n",
    "                   [\"C\", 100], [\"D\", 300]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "k = 2\n",
    "\n",
    "## start your code below\n",
    "largest_k = df.nlargest(k, 'col_B')\n",
    "## end your code here\n",
    "\n",
    "largest_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIUaA19sPe8C"
   },
   "source": [
    "### 169. Delete the rows that have NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGDbUsNFPe8C",
    "outputId": "7ef6fbd2-54e9-4b80-9182-7de9c1117d40",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.981108Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", np.NaN], [\"B\", 2],\n",
    "                   [\"C\", np.NaN], [\"D\", 4]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "## start your code below\n",
    "df = df.dropna()\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owHFel_vPe8C"
   },
   "source": [
    "### 171. Fill NaN values with column mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXmoI6UDPe8C",
    "outputId": "fc58c397-1407-401a-bbbd-90041862f1e5",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.981829Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", np.NaN], [\"B\", 2],\n",
    "                   [\"C\", np.NaN], [\"D\", 4]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "## start your code below\n",
    "df[\"col_B\"] = df[\"col_B\"].fillna(df[\"col_B\"].mean())\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAW4_HLmPe8D"
   },
   "source": [
    "### 173. Swap two rows of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C80h71zHPe8D",
    "outputId": "d69dcfec-c584-4b5c-f447-b4d554a2f13f",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.982461Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
    "                   [\"C\", 3], [\"D\", 4]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "# swap second and last row\n",
    "row_1, row_2 = 1, 3\n",
    "\n",
    "## start your code below\n",
    "df.iloc[row_1], df.iloc[row_2] = df.iloc[row_2].copy(), df.iloc[row_1].copy()\n",
    "\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OH8J8lVVPe8D"
   },
   "source": [
    "### 174. Create a column \"col_D\" that contains the 2nd largest value in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwPfPPO4Pe8D",
    "outputId": "0f81e794-0ecb-45b6-9ef1-36bf3d622735",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.983108Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 2, 9],\n",
    "                   [2, 9, 3],\n",
    "                   [8, 5, 4]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "\n",
    "def second_largest(row):\n",
    "    sorted_row = sorted(row, reverse=True)\n",
    "    return sorted_row[1]\n",
    "\n",
    "df['col_D'] = df.apply(second_largest, axis=1)\n",
    "\n",
    "# end your code here\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyCGWaEyPe8D"
   },
   "source": [
    "### 176. Get the Group \"A\" of the dataframe by first grouping the dataframe and then using the group key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5EjNC6GPe8E",
    "outputId": "49595ad3-d391-4717-a2c3-e94c4f3ff0f8",
    "ExecuteTime": {
     "start_time": "2024-01-10T15:39:19.983770Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
    "                   [\"A\", 3], [\"D\", 4]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "group_A = df.groupby('col_A').get_group('A')\n",
    "\n",
    "## end your code here\n",
    "\n",
    "group_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6PWZhA_Pe8E"
   },
   "source": [
    "### 178. Get the rows where the value of \"col_A\" is equal to \"col_B\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "id": "VwiSSWd5Pe8E",
    "outputId": "8147f83e-209e-41a8-fc8e-706b40838aa7",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:20.625868Z",
     "start_time": "2024-01-10T15:39:20.364856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_A  col_B  col_C\n",
      "1      5      5      9\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 5, 9],\n",
    "                   [2, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "new_df = df[df['col_A'] == df['col_B']]\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBaZqoE1Pe8E"
   },
   "source": [
    "### 180. Sort the Data on col_A and col_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgE4yGt5Pe8F"
   },
   "source": [
    "col_A -> Ascending\n",
    "col_B -> Descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "id": "rIXbUrmUPe8F",
    "outputId": "e6225844-d1a1-4e93-943e-e3e6b0cc6cc6",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:21.338124Z",
     "start_time": "2024-01-10T15:39:20.615490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_A  col_B  col_C\n",
      "2      2      9      3\n",
      "1      2      5      9\n",
      "0      4      1      5\n",
      "3      8      5      8\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [2, 5, 9],\n",
    "                   [2, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "new_df = df.sort_values(by=['col_A', 'col_B'], ascending=[True, False])\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuV4_g_EPe8F"
   },
   "source": [
    "### 182. Get the mean of every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "id": "ziefgTwrPe8F",
    "outputId": "15599489-3c9f-499a-9133-3438ddd343e4",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:21.396110Z",
     "start_time": "2024-01-10T15:39:21.337376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_A    4.75\n",
      "col_B    5.00\n",
      "col_C    6.25\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 5, 9],\n",
    "                   [2, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "mean = df.mean()\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cd9kqXQPe8G"
   },
   "source": [
    "### 182. Get the mean of every row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "id": "QNmOWWiGPe8G",
    "outputId": "0105b52c-d308-47dd-f4a3-c2e62e7b0022",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:21.486925Z",
     "start_time": "2024-01-10T15:39:21.385552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3.333333\n",
      "1    6.333333\n",
      "2    4.666667\n",
      "3    7.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 5, 9],\n",
    "                   [2, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "mean = df.mean(axis=1)\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSbmaEiDPe8G"
   },
   "source": [
    "### 183. Concatentate the two DataFrames row-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "id": "2y5hJG5BPe8G",
    "outputId": "a777be01-fb23-43e9-f3e9-0c49da3d2d41",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:21.526564Z",
     "start_time": "2024-01-10T15:39:21.476452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col_A  col_B\n",
      "0     A      1\n",
      "1     B      2\n",
      "0     A      3\n",
      "1     C      4\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame([[\"A\", 1], [\"B\", 2]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "df2 = pd.DataFrame([[\"A\", 3], [\"C\", 4]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "## start your code below\n",
    "new_df = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uB6zGw2IPe8H"
   },
   "source": [
    "### 184. Concatentate the two DataFrames column-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "id": "Y1R5RLSxPe8H",
    "outputId": "16a2d7f1-eda4-4b3f-a82c-d70abfe3f939",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:21.663915Z",
     "start_time": "2024-01-10T15:39:21.524829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col_A  col_B col_C  col_D\n",
      "0     A      1     A      3\n",
      "1     B      2     C      4\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame([[\"A\", 1], [\"B\", 2]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "df2 = pd.DataFrame([[\"A\", 3], [\"C\", 4]],\n",
    "                  columns=[\"col_C\", \"col_D\"])\n",
    "\n",
    "## start your code below\n",
    "new_df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDT_fAddPe8H"
   },
   "source": [
    "### 185. Change the last two values in the last column to [2,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXi81-5PPe8H"
   },
   "source": [
    "Change 3 -> 2\n",
    "Change 8 -> 4\n",
    "\n",
    "**Note: You should do this in a single line of code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "id": "Js16VFnuPe8H",
    "outputId": "bae18e49-16b7-4085-e6bd-f7c95ce34c1a",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:21.698461Z",
     "start_time": "2024-01-10T15:39:21.639710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_A  col_B  col_C\n",
      "0      4      1      5\n",
      "1      5      5      9\n",
      "2      2      9      2\n",
      "3      8      5      4\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 5, 9],\n",
    "                   [2, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "df.iloc[-2:, -1] = [2, 4]\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Juf2-66Pe8I"
   },
   "source": [
    "### 186. Replace all '1' with '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "id": "nfmz1WmcPe8I",
    "outputId": "cc728c21-8072-4382-f276-80486ef01d0b",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:21.793074Z",
     "start_time": "2024-01-10T15:39:21.693025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_A  col_B  col_C\n",
      "0      4      2      5\n",
      "1      5      5      2\n",
      "2      2      9      3\n",
      "3      8      5      8\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 5, 1],\n",
    "                   [1, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "df.replace(1, 2, inplace=True)\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s30cVPk7Pe8I"
   },
   "source": [
    "### 187. Replace all '1' with '2' and '5' with '6' in a single line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "id": "5UJN-Hr7Pe8I",
    "outputId": "d59358db-757a-40ee-a48f-b4a8ce530ebf",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:21.881712Z",
     "start_time": "2024-01-10T15:39:21.792123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_A  col_B  col_C\n",
      "0      4      2      6\n",
      "1      6      6      2\n",
      "2      2      9      3\n",
      "3      8      6      8\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 5, 1],\n",
    "                   [1, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "df.replace({1: 2, 5: 6}, inplace=True)\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQgW4UhrPe8J"
   },
   "source": [
    "### 189. Convert the DataFrame to a list of lists. Don't include the header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "id": "1ywo_MqWPe8J",
    "outputId": "e884f5a0-32fd-440e-ae2c-c6417e1c88d0",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:21.964680Z",
     "start_time": "2024-01-10T15:39:21.838129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1, 5], [5, 5, 1], [1, 9, 3], [8, 5, 8]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 5, 1],\n",
    "                   [1, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "data_list = df.values.tolist()\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz1xs9mdPe8J"
   },
   "source": [
    "### 190. Add three new columns that show the cumulative sum of every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "id": "Gk9lYwGqPe8J",
    "outputId": "c9631ebe-2d63-4591-d0e8-dedbd164161a",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:22.031587Z",
     "start_time": "2024-01-10T15:39:21.964190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_A  col_B  col_C  cumsum_A  cumsum_B  cumsum_C\n",
      "0      4      1      5         4         1         5\n",
      "1      5      5      1         9         6         6\n",
      "2      1      9      3        10        15         9\n",
      "3      8      5      8        18        20        17\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 5, 1],\n",
    "                   [1, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "df['cumsum_A'] = df['col_A'].cumsum()\n",
    "df['cumsum_B'] = df['col_B'].cumsum()\n",
    "df['cumsum_C'] = df['col_C'].cumsum()\n",
    "## end your code here\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qCigFOXPe8K"
   },
   "source": [
    "### 191. Print the cumulative sum of every row in a new column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VayiPXaHPe8K"
   },
   "source": [
    "### In other words, make a column that stores the cumulative sum of the (sum of every row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "id": "uC9GxcZNPe8K",
    "outputId": "fdc11155-6038-4319-d8a9-77b0127f480c",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:22.126861Z",
     "start_time": "2024-01-10T15:39:22.012375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_A  col_B  col_C  cumsum_row\n",
      "0      4      1      5          10\n",
      "1      5      5      1          21\n",
      "2      1      9      3          34\n",
      "3      8      5      8          55\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 5, 1],\n",
    "                   [1, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "df['cumsum_row'] = df.sum(axis=1).cumsum()\n",
    "\n",
    "## end your code here\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Z5JOgHhPe8K"
   },
   "source": [
    "### 194. GroupBy col_A, then find the sum of col_B and mean of col_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "id": "-Rw6XlEaPe8K",
    "outputId": "cb116560-f209-4cdf-adf4-8e9e0ef3808a",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:22.182887Z",
     "start_time": "2024-01-10T15:39:22.115887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       col_B  col_C\ncol_A              \nA          6    6.5\nB          5    1.0\nC          9    3.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col_B</th>\n      <th>col_C</th>\n    </tr>\n    <tr>\n      <th>col_A</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A</th>\n      <td>6</td>\n      <td>6.5</td>\n    </tr>\n    <tr>\n      <th>B</th>\n      <td>5</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>C</th>\n      <td>9</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[\"A\", 1, 5],\n",
    "                   [\"B\", 5, 1],\n",
    "                   [\"C\", 9, 3],\n",
    "                   [\"A\", 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "result = df.groupby('col_A').agg({'col_B': 'sum', 'col_C': 'mean'})\n",
    "\n",
    "## end your code here\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dA4_0kDGPe8L"
   },
   "source": [
    "### 195. Find the correlation between every pair of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "id": "20Luc7I3Pe8L",
    "outputId": "208d3c5d-e0e3-4d87-974f-a1f9af788f10",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:22.287957Z",
     "start_time": "2024-01-10T15:39:22.171343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          col_A     col_B     col_C\n",
      "col_A  1.000000 -0.424264  0.599377\n",
      "col_B -0.424264  1.000000 -0.273434\n",
      "col_C  0.599377 -0.273434  1.000000\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 5, 1],\n",
    "                   [1, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "new_df = df.corr()\n",
    "## end your code here\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bPI8RosPe8L"
   },
   "source": [
    "### 198. Merge the two dataframes using the join() method on col_A.\n",
    "참고) Note that the `join()` method is similar to the `merge()` method, but it operates on the index by default and has a simplified syntax.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "id": "CnCojcBXPe8L",
    "outputId": "7815e702-7d4b-4542-9339-f567d309950b",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:22.376689Z",
     "start_time": "2024-01-10T15:39:22.276657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col_A  col_B  col_C\n",
      "0     A    1.0    3.0\n",
      "1     B    2.0    NaN\n",
      "2     C    NaN    4.0\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame([[\"A\", 1], [\"B\", 2]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "df2 = pd.DataFrame([[\"A\", 3], [\"C\", 4]],\n",
    "                  columns=[\"col_A\", \"col_C\"])\n",
    "\n",
    "## start your code below\n",
    "new_df = df1.set_index(\"col_A\").join(df2.set_index(\"col_A\"), how=\"outer\")\n",
    "\n",
    "new_df.reset_index(inplace=True)\n",
    "# end your code here\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57TodkT8Pe8M"
   },
   "source": [
    "### 199. Perform the full outer join on the two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "id": "VQOIzyYOPe8M",
    "outputId": "e2bb393e-d0e6-403e-b29a-35f516e38c75",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:22.519455Z",
     "start_time": "2024-01-10T15:39:22.365400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col_A  col_B  col_C\n",
      "0     A    1.0    3.0\n",
      "1     B    2.0    NaN\n",
      "2     C    NaN    4.0\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame([[\"A\", 1], [\"B\", 2]],\n",
    "                  columns=[\"col_A\", \"col_B\"])\n",
    "\n",
    "df2 = pd.DataFrame([[\"A\", 3], [\"C\", 4]],\n",
    "                  columns=[\"col_A\", \"col_C\"])\n",
    "\n",
    "## start your code below\n",
    "new_df = pd.merge(df1, df2, on=\"col_A\", how=\"outer\")\n",
    "## end your code here\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riDJXX7LPe8M"
   },
   "source": [
    "### 200. Convert the DataFrame to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "id": "xRSfy5E3Pe8M",
    "outputId": "b53ac994-e2d9-4b91-9c45-eba13c91a410",
    "ExecuteTime": {
     "end_time": "2024-01-10T15:39:22.590441Z",
     "start_time": "2024-01-10T15:39:22.518358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'col_A': [4, 5, 1, 8], 'col_B': [1, 5, 9, 5], 'col_C': [5, 1, 3, 8]}"
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 1, 5],\n",
    "                   [5, 5, 1],\n",
    "                   [1, 9, 3],\n",
    "                   [8, 5, 8]],\n",
    "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
    "\n",
    "\n",
    "## start your code below\n",
    "dict_df = df.to_dict(orient='list')\n",
    "\n",
    "## end your code here\n",
    "\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_DkYvWnPe8N"
   },
   "source": [
    "### 끝.\n",
    "### 고생하셨습니다."
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "07dac775df544b37af03c6a6f77c87ab",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 2,
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
